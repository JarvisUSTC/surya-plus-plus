{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hf_shared/hfai_envs/wangjiawei/wjw_surya_0/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/hf_shared/hfai_envs/wangjiawei/wjw_surya_0/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/hf_shared/hfai_envs/wangjiawei/wjw_surya_0/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detection model vikp/surya_det2 on device cuda with dtype torch.float16\n",
      "Loaded recognition model vikp/surya_rec on device cuda with dtype torch.float16\n",
      "Loaded detection model vikp/surya_layout2 on device cuda with dtype torch.float16\n",
      "Loaded reading order model vikp/surya_order on device cuda with dtype torch.float16\n"
     ]
    }
   ],
   "source": [
    "# 第一次运行需要加代理下载huggingface权重\n",
    "from PIL import Image\n",
    "from surya.ocr import run_ocr\n",
    "from surya.model.detection.segformer import load_model as load_det_model\n",
    "from surya.model.detection.segformer import load_processor as load_det_processor\n",
    "from surya.model.recognition.model import load_model as load_rec_model\n",
    "from surya.model.recognition.processor import load_processor as load_rec_processor\n",
    "from surya.model.ordering.processor import load_processor as load_ordering_processor\n",
    "from surya.model.ordering.model import load_model as load_ordering_model\n",
    "from surya.settings import settings\n",
    "\n",
    "# det_processor, det_model = load_det_processor(checkpoint=settings.DETECTOR_MATH_MODEL_CHECKPOINT), load_det_model(checkpoint=settings.DETECTOR_MATH_MODEL_CHECKPOINT)\n",
    "det_processor, det_model = load_det_processor(), load_det_model()\n",
    "rec_model, rec_processor = load_rec_model(), load_rec_processor()\n",
    "layout_model = load_det_model(checkpoint=settings.LAYOUT_MODEL_CHECKPOINT)\n",
    "layout_processor = load_det_processor(checkpoint=settings.LAYOUT_MODEL_CHECKPOINT)\n",
    "order_model = load_ordering_model()\n",
    "order_processor = load_ordering_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Blank',\n",
       " 1: 'Caption',\n",
       " 2: 'Footnote',\n",
       " 3: 'Formula',\n",
       " 4: 'List-item',\n",
       " 5: 'Page-footer',\n",
       " 6: 'Page-header',\n",
       " 7: 'Picture',\n",
       " 8: 'Section-header',\n",
       " 9: 'Table',\n",
       " 10: 'Text',\n",
       " 11: 'Title'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_PATH = \"/weka-jd/prod/deepseek/permanent/wangjiawei/workspace/surya/test_data/04194-00/26194194_0026.input.png\"\n",
    "IMAGE_PATH = \"/weka-jd/prod/deepseek/permanent/wangjiawei/workspace/surya/test_data/10015308/14_1.png\"\n",
    "image = Image.open(IMAGE_PATH)\n",
    "langs = [\"en\", \"zh\"] # Replace with your languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Finding reading order: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from surya.ocr import run_ocr\n",
    "from surya.detection import batch_text_detection\n",
    "from surya.layout import batch_layout_detection\n",
    "from surya.ordering import batch_ordering\n",
    "import copy\n",
    "\n",
    "ocr_predictions = run_ocr([image], [langs], det_model, det_processor, rec_model, rec_processor)\n",
    "text_line_predictions = batch_text_detection([image], det_model, det_processor)\n",
    "layout_predictions = batch_layout_detection([image], layout_model, layout_processor, copy.deepcopy(text_line_predictions))\n",
    "\n",
    "# bboxes = [line_bbox.bbox for i, line_bbox in enumerate(ocr_predictions[0].text_lines)]\n",
    "bboxes = [layout_box.bbox for i, layout_box in enumerate(layout_predictions[0].bboxes)]\n",
    "order_predictions = batch_ordering([image], [bboxes], order_model, order_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the predictions of ocr, layout, order into the format of the output\n",
    "\"\"\"\n",
    "{\n",
    "  \"text\": \"<deepseek_image>\\nEilish was finding it hard to breathe and closed her eyes.\\nAnya had returned to her place in the circle next to her sister. \\\"Are you all right?\\\"\\nEilish shook her head no.\\nAnya grabbed her hand and squeezed. \\\"Try to hold on.\\\"\\nFina began her call to the spirits. She rang the bell three times and stood regal before the small fire, her breasts bare, her thick dark hair falling to her shoulders. She raised both hands to the heavens as four warlocks in their hooded robes broke from the circle to approach the frightened stag. They had drugged the deer so as not to have him panic, but he struggled nonetheless as the warlocks deftly cut his throat, and the blood of the sacrificed animal ran in a pool beneath Fina's feet.\\nEilish began to hyperventilate and fought the pull into the circle’s center.\\nFina's voice rose strong, \\\"On this night, all roads cross, all gates open. All nights, all dreams, all worlds have come together at the death of the old year. On this night of ancients, the gates to the other world are opened wide, and the veil grows thin. We seek guidance from those who walked before us.\\\"\\nThe men had severed the antlers from the now-dead buck and were raising it to place on Fina's head when Eilish felt herself dropping into an unconscious state, and the spirit of Rhiannon entered her. The winds picked up as she broke from the circle, holding her own hands skyward, her head back as she shouted. \\\"I invoke you, Hekate. You of roads and crossways, Goddess of the Heavens, the Underworld, and the sea. You who among the tombs, dancing with the dead souls. Respond to the daughter of Rhiannon.\\\"\\nFina turned and looked on in horror. What was she doing? This wasn't part of the ritual! She looked at Warrick, who shook his head, sensing a power he didn't wish to confront in Eilish, at least not in front of the coven. The men carrying the antlers stopped in their tracks as Eilish approached, and Fina backed away. The men looked at each other in confusion but proceeded to secure the antlers to Eilish's head. The coven was taken aback by this change in the ritual and momentarily stopped their drumming as they watched in awe as the antlers were placed on Eilish, and her snow-white hair slowly turned red as the blood of the buck ran through her hair and down her face, dripping upon her breast.\\n<deepseek_image>\\nBoth Ian and Carter had been quiet, but their eyes were glued to the drama playing out before them. Carter seemed mesmerized by what was happening, his eyes never leaving Anya.\\nSuddenly Ian stood up in the tree, and Carter looked at him. \\\"What’s wrong? This is some freak show, to begin with, but when you get rattled, I get anxious.\\\" Ian felt his heart hammering in his chest when Eilish entered a semi-conscious state and felt the entity of the being that entered her. His beast roared inside, but he knew he could not step in. \\\"This isn’t right; something is happening to Eilish.\\\"\\nCarter swung his head back to the ritual in progress and saw the antlers on her head, blood dripping. \\\"Fuck me, bro, this is like something satanic. I don’t like this. I don’t like Anya being down there in the middle of this.\\\"\\nIan whispered. \\\"I feel the same, Carter, but here’s the deal. It’s not satanic; this ritual is about honoring the harvest and bounty of a good year. It’s as old as time. Your child will be a part of this. And that woman who was leading is your soon-to-be Mother-in-law. Anya will teach you. But I think Eilish just changed up the rules of this game and things are about to ramp up.\\\"\\nCarter's head was spinning. He hadn't thought about the ramifications of having a child with a witch. Of course, the baby would be taught these rituals and have their power. He was beginning to understand why the coven wouldn’t receive him with open arms as he listened to Ian's explanation.\\n\",\n",
    "  \"images\": [\n",
    "    \"input.png\",\n",
    "    \"image_0000.png\"\n",
    "  ],\n",
    "  \"similarities\": [\n",
    "    1.0,\n",
    "    1.0\n",
    "  ],\n",
    "  \"type\": \"interleave\",\n",
    "  \"image_tag\": \"<deepseek_image>\",\n",
    "  \"template\": \"DOUBLE-DOUBLE\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# IMAGE_PATH = \"/weka-jd/prod/deepseek/permanent/wangjiawei/workspace/surya/test_data/04194-00/26194194_0026.input.png\"\n",
    "# IMAGE_PATH = \"/weka-jd/prod/deepseek/permanent/wangjiawei/workspace/surya/test_data/10015308/14_1.png\"\n",
    "image = Image.open(IMAGE_PATH)\n",
    "langs = [\"en\", \"zh\"] # Replace with your languages\n",
    "\n",
    "save_path = \"/weka-jd/prod/deepseek/permanent/wangjiawei/workspace/surya/test_data/test\"\n",
    "image_name = IMAGE_PATH.split(\"/\")[-1]\n",
    "\n",
    "image.save(os.path.join(save_path, image_name))\n",
    "\n",
    "output = {\n",
    "    \"text\": \"<deepseek_image>\\n\",\n",
    "    \"images\": ['input.png'],\n",
    "    \"similarities\": [1.0],\n",
    "    \"type\": \"\", # Document\n",
    "    \"image_tag\": \"<deepseek_image>\",\n",
    "    \"template\": \"\" # I don't know what the key of \"template\" does mean\n",
    "}\n",
    "\n",
    "# Firstly, map the ocr id to the layout id\n",
    "layout_id_to_ocr_id = defaultdict(list)\n",
    "ocr_id_to_layout_id = {}\n",
    "for i, ocr_line in enumerate(ocr_predictions[0].text_lines):\n",
    "    for j, layout_line in enumerate(layout_predictions[0].bboxes):\n",
    "        if ocr_line.intersection_pct(layout_line) > 0.9:\n",
    "            ocr_id_to_layout_id[i] = j\n",
    "            layout_id_to_ocr_id[j].append(i)\n",
    "            break\n",
    "\n",
    "order = [b.position for b in order_predictions[0].bboxes]\n",
    "# Then, sort the layout id by the order\n",
    "layout_ids = [order.index(i) for i in range(len(order))]\n",
    "\n",
    "# Finally, generate the output\n",
    "additional_image_id = 0\n",
    "for layout_id in layout_ids:\n",
    "    ocr_ids = layout_id_to_ocr_id[layout_id]\n",
    "    layout_pred = layout_predictions[0].bboxes[layout_id]\n",
    "    label = layout_pred.label\n",
    "    # layout_model.config.id2label\n",
    "    \"\"\"\n",
    "    {0: 'Blank',\n",
    "    1: 'Caption',\n",
    "    2: 'Footnote',\n",
    "    3: 'Formula',\n",
    "    4: 'List-item',\n",
    "    5: 'Page-footer',\n",
    "    6: 'Page-header',\n",
    "    7: 'Picture',\n",
    "    8: 'Section-header',\n",
    "    9: 'Table',\n",
    "    10: 'Text',\n",
    "    11: 'Title'}\n",
    "    \"\"\"\n",
    "    if label not in ['Picture', 'Figure', 'Table']:\n",
    "        for ocr_id in ocr_ids:\n",
    "            # Two options here: append \"\\n\" at the end of each text-line or append \"\\n\" at the end of each paragraph (may be not precious)\n",
    "            # output[\"text\"] += ocr_predictions[0].text_lines[ocr_id].text + \"\\n\" \n",
    "            output[\"text\"] += ocr_predictions[0].text_lines[ocr_id].text\n",
    "        output[\"text\"] += \"\\n\"\n",
    "    elif label in ['Picture', 'Figure']:\n",
    "        # need to crop the image and save it as a new image\n",
    "\n",
    "        # crop the image\n",
    "        image = Image.open(IMAGE_PATH)\n",
    "        cropped_image = image.crop(layout_pred.bbox)\n",
    "        cropped_image.save(os.path.join(save_path,f\"{image_name.split('.')[0]}.image_{additional_image_id:04d}.png\"))\n",
    "\n",
    "        output[\"text\"] += \"<deepseek_image>\\n\"\n",
    "        output[\"images\"].append(f\"image_{additional_image_id:04d}.png\")\n",
    "        output[\"similarities\"].append(1.0)\n",
    "\n",
    "        additional_image_id += 1\n",
    "\n",
    "        for ocr_id in ocr_ids:\n",
    "            output[\"text\"] += ocr_predictions[0].text_lines[ocr_id].text + \"\\n\"\n",
    "    elif label == \"Table\":\n",
    "        # Take table in document as an image unless we have a tool to convert the table into a structured data\n",
    "        # need to crop the image and save it as a new image\n",
    "        # crop the image\n",
    "        image = Image.open(IMAGE_PATH)\n",
    "        cropped_image = image.crop(layout_pred.bbox)\n",
    "        cropped_image.save(os.path.join(save_path,f\"{image_name.split('.')[0]}.image_{additional_image_id:04d}.png\"))\n",
    "\n",
    "        output[\"text\"] += \"<deepseek_image>\\n\"\n",
    "        output[\"images\"].append(f\"image_{additional_image_id:04d}.png\")\n",
    "        output[\"similarities\"].append(1.0)\n",
    "\n",
    "        additional_image_id += 1\n",
    "\n",
    "        for ocr_id in ocr_ids:\n",
    "            output[\"text\"] += ocr_predictions[0].text_lines[ocr_id].text + \"\\n\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown label {label}\")\n",
    "    \n",
    "# save the output into a json file\n",
    "# there are many chinese word\n",
    "# so we need to save the file with utf-8\n",
    "import json\n",
    "with open(os.path.join(save_path,f\"{image_name.split('.')[0]}.text.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "# Visualize the Layout Results in Original Image (need to handcraft)\n",
    "\n",
    "# create an image copy\n",
    "image_c = image.copy()\n",
    "# 创建一个 ImageDraw 对象\n",
    "draw = ImageDraw.Draw(image_c)\n",
    "# draw the bounding boxes\n",
    "for i, layout_bbox in enumerate(layout_predictions[0].bboxes):\n",
    "    bbox = layout_bbox.bbox\n",
    "    label = layout_bbox.label\n",
    "    draw.rectangle(bbox, outline=\"red\", width=3)\n",
    "    draw.text((bbox[0], bbox[1]), label, fill=\"red\")\n",
    "\n",
    "# Visualize the OCR Results (text_line) in Original Image (need to handcraft)\n",
    "\n",
    "for i, line_bbox in enumerate(ocr_predictions[0].text_lines):\n",
    "    bbox = line_bbox.bbox\n",
    "    text = line_bbox.text\n",
    "    draw.rectangle(bbox, outline=\"green\", width=3)\n",
    "\n",
    "# Visualize the Reading Order Results in Original Image (need to handcraft)\n",
    "# sort the bboxes based on the order\n",
    "order_boxes = order_predictions[0].bboxes\n",
    "order_boxes = sorted(order_boxes, key=lambda x: x.position, reverse=False)\n",
    "for i, order_bbox in enumerate(order_boxes):\n",
    "    bbox = order_bbox.bbox\n",
    "    draw.rectangle(bbox, outline=\"blue\", width=3)\n",
    "    # draw arrow from the center of previous bbox to that of current bbox\n",
    "    if i > 0:\n",
    "        pre_center = ((order_boxes[i-1].bbox[0] + order_boxes[i-1].bbox[2])/2, (order_boxes[i-1].bbox[1] + order_boxes[i-1].bbox[3])/2)\n",
    "        cur_center = ((order_boxes[i].bbox[0] + order_boxes[i].bbox[2])/2, (order_boxes[i].bbox[1] + order_boxes[i].bbox[3])/2)\n",
    "        draw.line([pre_center, cur_center], fill=\"blue\", width=3)\n",
    "    \n",
    "\n",
    "image_c.save(os.path.join(save_path,f'{IMAGE_PATH.split(\"/\")[-1].split(\".\")[0]}_layout.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98.0, 307.0, 1848.0, 339.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_predictions[0].text_lines[0].bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_boxes = order_predictions[0].bboxes\n",
    "order_boxes = sorted(order_boxes, key=lambda x: x.position, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextLine(polygon=[[32.0, 83.0], [244.0, 83.0], [244.0, 100.0], [32.0, 100.0]], confidence=0.99072265625, text='that’s settled then! Let’s dig in.\"', bbox=[32.0, 83.0, 244.0, 100.0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_predictions[0].text_lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
